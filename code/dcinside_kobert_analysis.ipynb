{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ® ë””ì‹œì¸ì‚¬ì´ë“œ í¬ë¡¤ë§ + KoBERT ê°ì„±ë¶„ì„\n",
    "\n",
    "## í•™ìŠµ ëª©í‘œ\n",
    "1. **ë””ì‹œì¸ì‚¬ì´ë“œ ê°¤ëŸ¬ë¦¬** ê²Œì‹œê¸€ ë° ëŒ“ê¸€ í¬ë¡¤ë§\n",
    "2. **KoBERT ê¸°ë°˜ ê°ì„±ë¶„ì„** ìˆ˜í–‰\n",
    "3. **í˜ì˜¤í‘œí˜„ íƒì§€** ë° ë¶„ì„\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“š ëª©ì°¨\n",
    "1. [í™˜ê²½ ì„¤ì •](#1-í™˜ê²½-ì„¤ì •)\n",
    "2. [ê°¤ëŸ¬ë¦¬ ì„¤ì •](#2-ê°¤ëŸ¬ë¦¬-ì„¤ì •)\n",
    "3. [ê²Œì‹œê¸€ ëª©ë¡ ìˆ˜ì§‘](#3-ê²Œì‹œê¸€-ëª©ë¡-ìˆ˜ì§‘)\n",
    "4. [ëŒ“ê¸€ ìˆ˜ì§‘](#4-ëŒ“ê¸€-ìˆ˜ì§‘)\n",
    "5. [í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬](#5-í…ìŠ¤íŠ¸-ì „ì²˜ë¦¬)\n",
    "6. [KoBERT ê°ì„±ë¶„ì„](#6-kobert-ê°ì„±ë¶„ì„)\n",
    "7. [í˜ì˜¤í‘œí˜„ íƒì§€](#7-í˜ì˜¤í‘œí˜„-íƒì§€)\n",
    "8. [ì¢…í•© ë¶„ì„](#8-ì¢…í•©-ë¶„ì„)\n",
    "\n",
    "---\n",
    "\n",
    "## âš ï¸ ì£¼ì˜ì‚¬í•­\n",
    "- êµìœ¡/ì—°êµ¬ ëª©ì ìœ¼ë¡œë§Œ ì‚¬ìš©í•˜ì„¸ìš”\n",
    "- ê³¼ë„í•œ í¬ë¡¤ë§ì€ ì„œë²„ì— ë¶€ë‹´ì„ ì¤ë‹ˆë‹¤\n",
    "- ê°œì¸ì •ë³´ ë³´í˜¸ì— ìœ ì˜í•˜ì„¸ìš”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 1. í™˜ê²½ ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 1-1. ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜\n",
    "# ============================================\n",
    "\n",
    "!pip install requests beautifulsoup4 lxml -q\n",
    "!pip install konlpy -q\n",
    "!pip install pandas numpy matplotlib seaborn wordcloud -q\n",
    "!pip install transformers torch sentencepiece -q\n",
    "\n",
    "# Selenium (Colabìš©)\n",
    "!pip install selenium -q\n",
    "!apt-get update -qq\n",
    "!apt-get install -y chromium-chromedriver -qq\n",
    "\n",
    "print(\"âœ… ì„¤ì¹˜ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 1-2. Colab í™˜ê²½ ì„¤ì •\n",
    "# ============================================\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "\n",
    "def setup_colab():\n",
    "    print(\"ğŸ”„ Java ì„¤ì¹˜ ì¤‘...\")\n",
    "    os.system('apt-get install -y openjdk-11-jdk-headless -qq')\n",
    "    os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
    "    \n",
    "    print(\"ğŸ”„ í•œê¸€ í°íŠ¸ ì„¤ì¹˜ ì¤‘...\")\n",
    "    os.system('apt-get install -y fonts-nanum -qq')\n",
    "    fm._load_fontmanager()\n",
    "    \n",
    "    plt.rcParams['font.family'] = 'NanumBarunGothic'\n",
    "    plt.rcParams['axes.unicode_minus'] = False\n",
    "    \n",
    "    # Selenium ì„¤ì •\n",
    "    sys.path.insert(0, '/usr/lib/chromium-browser/chromedriver')\n",
    "    \n",
    "    print(\"âœ… ì™„ë£Œ!\")\n",
    "\n",
    "try:\n",
    "    import google.colab\n",
    "    setup_colab()\n",
    "    IN_COLAB = True\n",
    "except:\n",
    "    plt.rcParams['font.family'] = 'Malgun Gothic'\n",
    "    IN_COLAB = False\n",
    "    print(\"ë¡œì»¬ í™˜ê²½ì…ë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 1-3. ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸\n",
    "# ============================================\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "import re\n",
    "import json\n",
    "import time\n",
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "from urllib.parse import quote, urlencode\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from konlpy.tag import Okt\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline\n",
    "\n",
    "print(\"âœ… ì„í¬íŠ¸ ì™„ë£Œ!\")\n",
    "print(f\"ğŸ”§ GPU: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 2. ê°¤ëŸ¬ë¦¬ ì„¤ì •\n",
    "\n",
    "## ğŸ“Œ ë””ì‹œì¸ì‚¬ì´ë“œ êµ¬ì¡°\n",
    "```\n",
    "ê°¤ëŸ¬ë¦¬ (Gallery)\n",
    "    â†“\n",
    "ê²Œì‹œê¸€ ëª©ë¡ (List)\n",
    "    â†“\n",
    "ê²Œì‹œê¸€ ìƒì„¸ + ëŒ“ê¸€ (View + Comments)\n",
    "```\n",
    "\n",
    "## ğŸ”— ì£¼ìš” ê°¤ëŸ¬ë¦¬ ID ì˜ˆì‹œ\n",
    "| ê°¤ëŸ¬ë¦¬ | ID |\n",
    "|--------|----|\n",
    "| ì£¼ì‹ | `stock` |\n",
    "| ë¹„íŠ¸ì½”ì¸ | `bitcoins` |\n",
    "| ì•¼êµ¬ | `baseball_new10` |\n",
    "| êµ­ë‚´ì•¼êµ¬ | `kbaseball` |\n",
    "| ì¶•êµ¬ | `football_new6` |\n",
    "| ì •ì¹˜ | `politics` |\n",
    "| ì¸í„°ë„·ë°©ì†¡ | `ib` |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 2-1. ìˆ˜ì§‘ ì„¤ì •\n",
    "# ============================================\n",
    "\n",
    "# â¬‡ï¸â¬‡ï¸â¬‡ï¸ ì—¬ê¸°ë¥¼ ìˆ˜ì •í•˜ì„¸ìš”! â¬‡ï¸â¬‡ï¸â¬‡ï¸\n",
    "\n",
    "# ê°¤ëŸ¬ë¦¬ ID (URLì—ì„œ í™•ì¸: gall.dcinside.com/board/lists/?id=ì—¬ê¸°)\n",
    "GALLERY_ID = \"politics\"  # ì •ì¹˜ ê°¤ëŸ¬ë¦¬\n",
    "\n",
    "# ë˜ëŠ” ë§ˆì´ë„ˆ ê°¤ëŸ¬ë¦¬\n",
    "IS_MINOR = False  # ë§ˆì´ë„ˆ ê°¤ëŸ¬ë¦¬ë©´ True\n",
    "\n",
    "# ê²€ìƒ‰ í‚¤ì›Œë“œ (ì„ íƒì‚¬í•­, ë¹ˆ ë¬¸ìì—´ì´ë©´ ì „ì²´ ê¸€)\n",
    "KEYWORD = \"ì´íƒœì›\"  # ê²€ìƒ‰ì–´\n",
    "\n",
    "# ìˆ˜ì§‘ ì„¤ì •\n",
    "MAX_PAGES = 5           # ìˆ˜ì§‘í•  í˜ì´ì§€ ìˆ˜\n",
    "MAX_POSTS = 30          # ìµœëŒ€ ê²Œì‹œê¸€ ìˆ˜\n",
    "MAX_COMMENTS = 50       # ê²Œì‹œê¸€ë‹¹ ìµœëŒ€ ëŒ“ê¸€ ìˆ˜\n",
    "\n",
    "# â¬†ï¸â¬†ï¸â¬†ï¸ ì—¬ê¸°ë¥¼ ìˆ˜ì •í•˜ì„¸ìš”! â¬†ï¸â¬†ï¸â¬†ï¸\n",
    "\n",
    "print(f\"ğŸ® ê°¤ëŸ¬ë¦¬: {GALLERY_ID}\")\n",
    "print(f\"ğŸ” í‚¤ì›Œë“œ: {KEYWORD if KEYWORD else '(ì „ì²´)'}\")\n",
    "print(f\"ğŸ“„ í˜ì´ì§€: {MAX_PAGES}ê°œ\")\n",
    "print(f\"ğŸ“ ê²Œì‹œê¸€: ìµœëŒ€ {MAX_POSTS}ê°œ\")\n",
    "print(f\"ğŸ’¬ ëŒ“ê¸€: ê²Œì‹œê¸€ë‹¹ {MAX_COMMENTS}ê°œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 2-2. ìš”ì²­ í—¤ë” ì„¤ì •\n",
    "# ============================================\n",
    "\n",
    "# ë””ì‹œì¸ì‚¬ì´ë“œëŠ” User-Agentì™€ Referer ì²´í¬ë¥¼ í•¨\n",
    "HEADERS = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',\n",
    "    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',\n",
    "    'Accept-Language': 'ko-KR,ko;q=0.9,en-US;q=0.8,en;q=0.7',\n",
    "    'Accept-Encoding': 'gzip, deflate, br',\n",
    "    'Connection': 'keep-alive',\n",
    "    'Referer': 'https://gall.dcinside.com/',\n",
    "}\n",
    "\n",
    "# ì„¸ì…˜ ìƒì„± (ì¿ í‚¤ ìœ ì§€)\n",
    "session = requests.Session()\n",
    "session.headers.update(HEADERS)\n",
    "\n",
    "print(\"âœ… ì„¸ì…˜ ì„¤ì • ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 3. ê²Œì‹œê¸€ ëª©ë¡ ìˆ˜ì§‘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 3-1. ê°¤ëŸ¬ë¦¬ URL ìƒì„±\n",
    "# ============================================\n",
    "\n",
    "def get_gallery_url(gallery_id, page=1, keyword=\"\", is_minor=False):\n",
    "    \"\"\"\n",
    "    ë””ì‹œì¸ì‚¬ì´ë“œ ê°¤ëŸ¬ë¦¬ URL ìƒì„±\n",
    "    \"\"\"\n",
    "    if is_minor:\n",
    "        base = \"https://gall.dcinside.com/mgallery/board/lists/\"\n",
    "    else:\n",
    "        base = \"https://gall.dcinside.com/board/lists/\"\n",
    "    \n",
    "    params = {\n",
    "        'id': gallery_id,\n",
    "        'page': page,\n",
    "    }\n",
    "    \n",
    "    if keyword:\n",
    "        params['s_type'] = 'search_subject_memo'  # ì œëª©+ë‚´ìš© ê²€ìƒ‰\n",
    "        params['s_keyword'] = keyword\n",
    "    \n",
    "    url = base + \"?\" + urlencode(params)\n",
    "    return url\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸\n",
    "test_url = get_gallery_url(GALLERY_ID, 1, KEYWORD, IS_MINOR)\n",
    "print(f\"ğŸ”— URL: {test_url}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 3-2. ê²Œì‹œê¸€ ëª©ë¡ í¬ë¡¤ë§ í•¨ìˆ˜\n",
    "# ============================================\n",
    "\n",
    "def get_post_list(gallery_id, page=1, keyword=\"\", is_minor=False):\n",
    "    \"\"\"\n",
    "    ê°¤ëŸ¬ë¦¬ í˜ì´ì§€ì—ì„œ ê²Œì‹œê¸€ ëª©ë¡ ìˆ˜ì§‘\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    list : ê²Œì‹œê¸€ ì •ë³´ ë¦¬ìŠ¤íŠ¸\n",
    "    \"\"\"\n",
    "    \n",
    "    posts = []\n",
    "    url = get_gallery_url(gallery_id, page, keyword, is_minor)\n",
    "    \n",
    "    try:\n",
    "        response = session.get(url, timeout=15)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        soup = BeautifulSoup(response.text, 'lxml')\n",
    "        \n",
    "        # ê²Œì‹œê¸€ ëª©ë¡ ì°¾ê¸°\n",
    "        post_table = soup.select('tr.ub-content.us-post')\n",
    "        \n",
    "        for row in post_table:\n",
    "            try:\n",
    "                # ê¸€ë²ˆí˜¸\n",
    "                num_elem = row.select_one('td.gall_num')\n",
    "                post_num = num_elem.get_text(strip=True) if num_elem else \"\"\n",
    "                \n",
    "                # ê³µì§€, ì„¤ë¬¸ ë“± ì œì™¸\n",
    "                if not post_num.isdigit():\n",
    "                    continue\n",
    "                \n",
    "                # ì œëª©\n",
    "                title_elem = row.select_one('td.gall_tit a:first-child')\n",
    "                if not title_elem:\n",
    "                    continue\n",
    "                title = title_elem.get_text(strip=True)\n",
    "                href = title_elem.get('href', '')\n",
    "                \n",
    "                # ëŒ“ê¸€ ìˆ˜\n",
    "                reply_elem = row.select_one('td.gall_tit a.reply_numbox')\n",
    "                reply_count = 0\n",
    "                if reply_elem:\n",
    "                    reply_text = reply_elem.get_text(strip=True)\n",
    "                    reply_match = re.search(r'\\d+', reply_text)\n",
    "                    if reply_match:\n",
    "                        reply_count = int(reply_match.group())\n",
    "                \n",
    "                # ì‘ì„±ì\n",
    "                writer_elem = row.select_one('td.gall_writer')\n",
    "                writer = writer_elem.get_text(strip=True) if writer_elem else \"\"\n",
    "                \n",
    "                # ì¡°íšŒìˆ˜\n",
    "                count_elem = row.select_one('td.gall_count')\n",
    "                view_count = count_elem.get_text(strip=True) if count_elem else \"0\"\n",
    "                \n",
    "                # ì¶”ì²œìˆ˜\n",
    "                recommend_elem = row.select_one('td.gall_recommend')\n",
    "                recommend = recommend_elem.get_text(strip=True) if recommend_elem else \"0\"\n",
    "                \n",
    "                # ë‚ ì§œ\n",
    "                date_elem = row.select_one('td.gall_date')\n",
    "                date = date_elem.get('title', '') if date_elem else \"\"\n",
    "                \n",
    "                posts.append({\n",
    "                    'num': post_num,\n",
    "                    'title': title,\n",
    "                    'url': 'https://gall.dcinside.com' + href if href.startswith('/') else href,\n",
    "                    'writer': writer,\n",
    "                    'view_count': view_count,\n",
    "                    'recommend': recommend,\n",
    "                    'reply_count': reply_count,\n",
    "                    'date': date,\n",
    "                })\n",
    "                \n",
    "            except Exception as e:\n",
    "                continue\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   âš ï¸ ì˜¤ë¥˜: {e}\")\n",
    "    \n",
    "    return posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 3-3. ì—¬ëŸ¬ í˜ì´ì§€ ê²Œì‹œê¸€ ìˆ˜ì§‘\n",
    "# ============================================\n",
    "\n",
    "all_posts = []\n",
    "\n",
    "print(f\"ğŸ”„ '{GALLERY_ID}' ê°¤ëŸ¬ë¦¬ ê²Œì‹œê¸€ ìˆ˜ì§‘ ì¤‘...\")\n",
    "if KEYWORD:\n",
    "    print(f\"   ê²€ìƒ‰ì–´: {KEYWORD}\")\n",
    "print()\n",
    "\n",
    "for page in range(1, MAX_PAGES + 1):\n",
    "    posts = get_post_list(GALLERY_ID, page, KEYWORD, IS_MINOR)\n",
    "    \n",
    "    if not posts:\n",
    "        print(f\"   í˜ì´ì§€ {page}: ê²Œì‹œê¸€ ì—†ìŒ\")\n",
    "        break\n",
    "    \n",
    "    all_posts.extend(posts)\n",
    "    print(f\"   í˜ì´ì§€ {page}: {len(posts)}ê°œ ìˆ˜ì§‘ (ì´ {len(all_posts)}ê°œ)\")\n",
    "    \n",
    "    if len(all_posts) >= MAX_POSTS:\n",
    "        break\n",
    "    \n",
    "    time.sleep(0.5)  # ì„œë²„ ë¶€ë‹´ ë°©ì§€\n",
    "\n",
    "# ìµœëŒ€ ê°œìˆ˜ ì œí•œ\n",
    "all_posts = all_posts[:MAX_POSTS]\n",
    "\n",
    "print(f\"\\nâœ… ì´ {len(all_posts)}ê°œ ê²Œì‹œê¸€ ìˆ˜ì§‘ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 3-4. ìˆ˜ì§‘ëœ ê²Œì‹œê¸€ í™•ì¸\n",
    "# ============================================\n",
    "\n",
    "if all_posts:\n",
    "    print(\"\\nğŸ“‹ ìˆ˜ì§‘ëœ ê²Œì‹œê¸€:\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    for i, post in enumerate(all_posts[:10], 1):\n",
    "        title = post['title'][:40] + \"...\" if len(post['title']) > 40 else post['title']\n",
    "        print(f\"{i}. {title}\")\n",
    "        print(f\"   ğŸ‘¤ {post['writer']} | ğŸ‘ï¸ {post['view_count']} | ğŸ’¬ {post['reply_count']} | ğŸ‘ {post['recommend']}\")\n",
    "else:\n",
    "    print(\"âŒ ìˆ˜ì§‘ëœ ê²Œì‹œê¸€ì´ ì—†ìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 4. ëŒ“ê¸€ ìˆ˜ì§‘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 4-1. ê²Œì‹œê¸€ ìƒì„¸ ë° ëŒ“ê¸€ ìˆ˜ì§‘ í•¨ìˆ˜\n",
    "# ============================================\n",
    "\n",
    "def get_post_comments(post_url, gallery_id, post_num, is_minor=False, max_comments=50):\n",
    "    \"\"\"\n",
    "    ê²Œì‹œê¸€ì˜ ë³¸ë¬¸ê³¼ ëŒ“ê¸€ ìˆ˜ì§‘\n",
    "    \n",
    "    ë””ì‹œì¸ì‚¬ì´ë“œ ëŒ“ê¸€ì€ AJAXë¡œ ë¡œë“œë¨\n",
    "    \"\"\"\n",
    "    \n",
    "    result = {\n",
    "        'content': '',\n",
    "        'comments': []\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        # 1. ê²Œì‹œê¸€ í˜ì´ì§€ ì ‘ê·¼ (e_s_n_o ê°’ íšë“)\n",
    "        response = session.get(post_url, timeout=15)\n",
    "        soup = BeautifulSoup(response.text, 'lxml')\n",
    "        \n",
    "        # ë³¸ë¬¸ ì¶”ì¶œ\n",
    "        content_elem = soup.select_one('div.write_div')\n",
    "        if content_elem:\n",
    "            result['content'] = content_elem.get_text(strip=True)\n",
    "        \n",
    "        # e_s_n_o ê°’ ì°¾ê¸° (ëŒ“ê¸€ APIì— í•„ìš”)\n",
    "        e_s_n_o = \"\"\n",
    "        scripts = soup.find_all('script')\n",
    "        for script in scripts:\n",
    "            if script.string and 'e_s_n_o' in str(script.string):\n",
    "                match = re.search(r\"e_s_n_o\\s*=\\s*['\\\"]([^'\\\"]+)['\\\"]\", str(script.string))\n",
    "                if match:\n",
    "                    e_s_n_o = match.group(1)\n",
    "                    break\n",
    "        \n",
    "        # 2. ëŒ“ê¸€ API í˜¸ì¶œ\n",
    "        if is_minor:\n",
    "            comment_url = \"https://gall.dcinside.com/mgallery/board/comment/\"\n",
    "        else:\n",
    "            comment_url = \"https://gall.dcinside.com/board/comment/\"\n",
    "        \n",
    "        comment_headers = HEADERS.copy()\n",
    "        comment_headers['X-Requested-With'] = 'XMLHttpRequest'\n",
    "        comment_headers['Content-Type'] = 'application/x-www-form-urlencoded; charset=UTF-8'\n",
    "        comment_headers['Referer'] = post_url\n",
    "        \n",
    "        # ëŒ“ê¸€ ë°ì´í„° ìš”ì²­\n",
    "        data = {\n",
    "            'id': gallery_id,\n",
    "            'no': post_num,\n",
    "            'cmt_id': gallery_id,\n",
    "            'cmt_no': post_num,\n",
    "            'e_s_n_o': e_s_n_o,\n",
    "            'comment_page': 1,\n",
    "            'sort': '',\n",
    "            '_GALLTYPE_': 'M' if is_minor else 'G',\n",
    "        }\n",
    "        \n",
    "        comment_response = session.post(comment_url, data=data, headers=comment_headers, timeout=15)\n",
    "        \n",
    "        if comment_response.status_code == 200:\n",
    "            try:\n",
    "                comment_data = comment_response.json()\n",
    "                comments_html = comment_data.get('comments', '')\n",
    "                \n",
    "                if comments_html:\n",
    "                    comment_soup = BeautifulSoup(comments_html, 'lxml')\n",
    "                    comment_items = comment_soup.select('li.ub-content')\n",
    "                    \n",
    "                    for item in comment_items[:max_comments]:\n",
    "                        # ëŒ“ê¸€ ë‚´ìš©\n",
    "                        text_elem = item.select_one('p.usertxt')\n",
    "                        if not text_elem:\n",
    "                            continue\n",
    "                        text = text_elem.get_text(strip=True)\n",
    "                        \n",
    "                        # ì‘ì„±ì\n",
    "                        writer_elem = item.select_one('span.nickname')\n",
    "                        writer = writer_elem.get_text(strip=True) if writer_elem else \"\"\n",
    "                        \n",
    "                        # ë‚ ì§œ\n",
    "                        date_elem = item.select_one('span.date_time')\n",
    "                        date = date_elem.get_text(strip=True) if date_elem else \"\"\n",
    "                        \n",
    "                        result['comments'].append({\n",
    "                            'text': text,\n",
    "                            'writer': writer,\n",
    "                            'date': date,\n",
    "                        })\n",
    "                        \n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "    except Exception as e:\n",
    "        pass\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 4-2. ëª¨ë“  ê²Œì‹œê¸€ì—ì„œ ëŒ“ê¸€ ìˆ˜ì§‘\n",
    "# ============================================\n",
    "\n",
    "all_comments = []\n",
    "all_contents = []\n",
    "\n",
    "if all_posts:\n",
    "    print(f\"ğŸ”„ {len(all_posts)}ê°œ ê²Œì‹œê¸€ì—ì„œ ëŒ“ê¸€ ìˆ˜ì§‘ ì¤‘...\\n\")\n",
    "    \n",
    "    for i, post in enumerate(all_posts, 1):\n",
    "        title_short = post['title'][:35] + \"...\" if len(post['title']) > 35 else post['title']\n",
    "        print(f\"[{i}/{len(all_posts)}] {title_short}\")\n",
    "        \n",
    "        # ëŒ“ê¸€ ìˆ˜ì§‘\n",
    "        result = get_post_comments(\n",
    "            post['url'], \n",
    "            GALLERY_ID, \n",
    "            post['num'], \n",
    "            IS_MINOR, \n",
    "            MAX_COMMENTS\n",
    "        )\n",
    "        \n",
    "        # ë³¸ë¬¸ ì €ì¥\n",
    "        if result['content']:\n",
    "            all_contents.append({\n",
    "                'type': 'post',\n",
    "                'text': result['content'],\n",
    "                'title': post['title'],\n",
    "                'writer': post['writer'],\n",
    "                'url': post['url'],\n",
    "            })\n",
    "        \n",
    "        # ëŒ“ê¸€ ì €ì¥\n",
    "        for comment in result['comments']:\n",
    "            comment['type'] = 'comment'\n",
    "            comment['post_title'] = post['title']\n",
    "            comment['post_url'] = post['url']\n",
    "            all_comments.append(comment)\n",
    "        \n",
    "        print(f\"      âœ… ëŒ“ê¸€ {len(result['comments'])}ê°œ\")\n",
    "        \n",
    "        time.sleep(0.5)  # ì„œë²„ ë¶€ë‹´ ë°©ì§€\n",
    "    \n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"âœ… ì´ {len(all_comments)}ê°œ ëŒ“ê¸€ ìˆ˜ì§‘ ì™„ë£Œ!\")\n",
    "    print(f\"âœ… ì´ {len(all_contents)}ê°œ ë³¸ë¬¸ ìˆ˜ì§‘ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 4-3. ìƒ˜í”Œ ë°ì´í„° (ìˆ˜ì§‘ ì‹¤íŒ¨ ì‹œ)\n",
    "# ============================================\n",
    "\n",
    "def create_sample_dc_data():\n",
    "    \"\"\"ë””ì‹œì¸ì‚¬ì´ë“œ ìŠ¤íƒ€ì¼ ìƒ˜í”Œ ë°ì´í„°\"\"\"\n",
    "    samples = [\n",
    "        # ì¼ë°˜ ëŒ“ê¸€\n",
    "        {\"text\": \"ã„¹ã…‡ ì¸ì • ì´ê±´ ë§ëŠ” ë§ì´ë„¤\", \"likes\": 45},\n",
    "        {\"text\": \"ì•„ë‹ˆ ì´ê²Œ ë­” ì†Œë¦¬ì•¼ ã…‹ã…‹ã…‹ã…‹\", \"likes\": 32},\n",
    "        {\"text\": \"ì™€ ì§„ì§œ ì—­ëŒ€ê¸‰ì´ë‹¤\", \"likes\": 28},\n",
    "        {\"text\": \"ì´ê±° ì‹¤í™”ëƒ?\", \"likes\": 25},\n",
    "        {\"text\": \"ã…‡ã…ˆ ì™„ì „ ê³µê°\", \"likes\": 22},\n",
    "        \n",
    "        # ë¹„íŒì  ëŒ“ê¸€\n",
    "        {\"text\": \"ì´ê²Œ ë‚˜ë¼ëƒ ì§„ì§œ\", \"likes\": 156},\n",
    "        {\"text\": \"ì±…ì„ì§€ëŠ” ë†ˆì´ ì—†ë„¤ ã…‹ã…‹\", \"likes\": 134},\n",
    "        {\"text\": \"ì•„ì§ë„ ì´ ëª¨ì–‘ì´ëƒ\", \"likes\": 98},\n",
    "        {\"text\": \"ì •ì‹  ì°¨ë ¤ë¼ ì§„ì§œ\", \"likes\": 87},\n",
    "        {\"text\": \"ë‹µì´ ì—†ë‹¤ ë‹µì´ ì—†ì–´\", \"likes\": 76},\n",
    "        \n",
    "        # ì •ì¹˜ì  ëŒ“ê¸€\n",
    "        {\"text\": \"ì¢ŒíŒŒë“¤ íŠ¹ì§• ë§¨ë‚  ì €ëŸ¬ë©´ì„œ ë‚¨íƒ“í•¨\", \"likes\": 65},\n",
    "        {\"text\": \"ìˆ˜ê¼´ë“¤ì€ ë­˜ í•´ë„ ì°¬ì–‘ì´ë„¤\", \"likes\": 54},\n",
    "        {\"text\": \"586 ê¼°ëŒ€ë“¤ì´ ë¬¸ì œì•¼\", \"likes\": 48},\n",
    "        {\"text\": \"í‹€ë”±ë“¤ íˆ¬í‘œ ì˜ëª»í•´ì„œ ì´ ì§€ê²½\", \"likes\": 42},\n",
    "        {\"text\": \"MZë“¤ì€ ë§¨ë‚  ë¶ˆí‰ë§Œ\", \"likes\": 38},\n",
    "        \n",
    "        # í˜ì˜¤ í‘œí˜„\n",
    "        {\"text\": \"ê·¸ìª½ ì• ë“¤ í•­ìƒ ì €ëŸ¬ë”ë¼\", \"likes\": 35},\n",
    "        {\"text\": \"ì—­ì‹œ í•œì‹¬í•˜ë„¤ ìˆ˜ì¤€ì´\", \"likes\": 32},\n",
    "        {\"text\": \"ë©ì²­í•œ ê²ƒë“¤ ã…‹ã…‹\", \"likes\": 28},\n",
    "        {\"text\": \"ë‹ˆë“¤ì´ ë­˜ ì•Œì•„\", \"likes\": 25},\n",
    "        \n",
    "        # ì¤‘ë¦½/ì •ë³´ì„±\n",
    "        {\"text\": \"íŒ©íŠ¸ì²´í¬ ì¢€ í•˜ê³  ë§í•´ë¼\", \"likes\": 67},\n",
    "        {\"text\": \"ì†ŒìŠ¤ ì–´ë””ëƒ\", \"likes\": 45},\n",
    "        {\"text\": \"ì¼ë‹¨ ê¸°ë‹¤ë ¤ë³´ì\", \"likes\": 34},\n",
    "        {\"text\": \"ì–‘ìª½ ë‹¤ ë¬¸ì œ ìˆìŒ\", \"likes\": 29},\n",
    "        {\"text\": \"ê°ê´€ì ìœ¼ë¡œ ë³´ë©´ ì´ê²Œ ë§ìŒ\", \"likes\": 25},\n",
    "    ]\n",
    "    \n",
    "    df = pd.DataFrame(samples)\n",
    "    df['type'] = 'comment'\n",
    "    df['post_title'] = f'{KEYWORD} ê´€ë ¨ ê¸€'\n",
    "    df['post_url'] = f'https://gall.dcinside.com/board/view/?id={GALLERY_ID}'\n",
    "    df['writer'] = [f'ã…‡ã…‡({i})' for i in range(len(df))]\n",
    "    df['date'] = '2024.10.29'\n",
    "    \n",
    "    return df\n",
    "\n",
    "# ë°ì´í„°í”„ë ˆì„ ìƒì„±\n",
    "if all_comments:\n",
    "    df_comments = pd.DataFrame(all_comments)\n",
    "    if 'likes' not in df_comments.columns:\n",
    "        df_comments['likes'] = 0\n",
    "else:\n",
    "    print(\"\\nâš ï¸ ëŒ“ê¸€ ìˆ˜ì§‘ ì‹¤íŒ¨. ìƒ˜í”Œ ë°ì´í„° ì‚¬ìš©.\")\n",
    "    df_comments = create_sample_dc_data()\n",
    "\n",
    "print(f\"\\nğŸ“Š ì´ {len(df_comments)}ê°œ ëŒ“ê¸€\")\n",
    "df_comments.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 5. í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 5-1. ë””ì‹œ íŠ¹í™” ì „ì²˜ë¦¬\n",
    "# ============================================\n",
    "\n",
    "okt = Okt()\n",
    "\n",
    "# ë””ì‹œì¸ì‚¬ì´ë“œ íŠ¹í™” ë¶ˆìš©ì–´\n",
    "DC_STOPWORDS = {\n",
    "    'ê²ƒ', 'ìˆ˜', 'ë“±', 'ë•Œ', 'ì¤‘', 'ì¢€', 'ë”', 'ë„¤', 'ê±°', 'ë­', 'ì œ', 'ì €', 'ê²Œ',\n",
    "    'ì´', 'ê·¸', 'ì €', 'ë‚˜', 'ë„ˆ', 'ìš°ë¦¬', 'ì €í¬', 'í•˜ë‹¤', 'ë˜ë‹¤', 'ìˆë‹¤', 'ì—†ë‹¤',\n",
    "    'ì§„ì§œ', 'ì •ë§', 'ë„ˆë¬´', 'ë§¤ìš°', 'ì•„ì£¼', 'ì™„ì „', 'ê·¸ëƒ¥', 'ë°”ë¡œ', 'ë‹¤ì‹œ', 'ë˜',\n",
    "    # ë””ì‹œ íŠ¹í™”\n",
    "    'ã…‹ã…‹', 'ã…‹ã…‹ã…‹', 'ã…‹ã…‹ã…‹ã…‹', 'ã…ã…', 'ã…ã…ã…', 'ã„¹ã…‡', 'ã…‡ã…ˆ', 'ã…‡ã…‡',\n",
    "    'ã„±ã„±', 'ã„´ã„´', 'ã…‡ã…‹', 'ã……ã„±', 'ê°¤ëŸ¬ë¦¬', 'ê¸€', 'ëŒ“ê¸€', 'ì¶”ì²œ', 'ë¹„ì¶”',\n",
    "}\n",
    "\n",
    "def clean_dc_text(text):\n",
    "    \"\"\"ë””ì‹œì¸ì‚¬ì´ë“œ í…ìŠ¤íŠ¸ ì •ê·œí™”\"\"\"\n",
    "    if pd.isna(text): return \"\"\n",
    "    text = str(text)\n",
    "    \n",
    "    # ë””ì‹œì½˜(ì´ëª¨í‹°ì½˜) ì œê±°\n",
    "    text = re.sub(r'\\[.*?\\]', '', text)\n",
    "    \n",
    "    # URL ì œê±°\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    \n",
    "    # ë°˜ë³µ ë¬¸ì ì •ê·œí™” (ã…‹ã…‹ã…‹ã…‹ã…‹ â†’ ã…‹ã…‹)\n",
    "    text = re.sub(r'(ã…‹|ã…|ã… |ã…œ|ã„·|ã…‚){3,}', r'\\1\\1', text)\n",
    "    \n",
    "    # íŠ¹ìˆ˜ë¬¸ì ì œê±° (í•œê¸€, ì˜ë¬¸, ìˆ«ìë§Œ ìœ ì§€)\n",
    "    text = re.sub(r'[^ê°€-í£a-zA-Z0-9\\s]', ' ', text)\n",
    "    \n",
    "    # ì—°ì† ê³µë°± ì œê±°\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    return text\n",
    "\n",
    "def extract_dc_keywords(text):\n",
    "    \"\"\"ë””ì‹œ ëŒ“ê¸€ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ\"\"\"\n",
    "    if not text: return []\n",
    "    nouns = okt.nouns(str(text))\n",
    "    return [w for w in nouns if len(w) >= 2 and w not in DC_STOPWORDS]\n",
    "\n",
    "# ì ìš©\n",
    "print(\"ğŸ”„ ì „ì²˜ë¦¬ ì¤‘...\")\n",
    "df_comments['cleaned_text'] = df_comments['text'].apply(clean_dc_text)\n",
    "df_comments['keywords'] = df_comments['cleaned_text'].apply(extract_dc_keywords)\n",
    "df_comments['text_length'] = df_comments['cleaned_text'].apply(len)\n",
    "\n",
    "# ë¹ˆ í…ìŠ¤íŠ¸ ì œê±°\n",
    "df_comments = df_comments[df_comments['text_length'] > 0].reset_index(drop=True)\n",
    "\n",
    "print(f\"âœ… ì™„ë£Œ! ({len(df_comments)}ê°œ)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 5-2. ì›Œë“œí´ë¼ìš°ë“œ\n",
    "# ============================================\n",
    "\n",
    "all_keywords = [w for kws in df_comments['keywords'] for w in kws]\n",
    "word_freq = Counter(all_keywords)\n",
    "\n",
    "if word_freq:\n",
    "    font_path = '/usr/share/fonts/truetype/nanum/NanumBarunGothic.ttf' if IN_COLAB else 'C:/Windows/Fonts/malgun.ttf'\n",
    "    \n",
    "    wc = WordCloud(\n",
    "        font_path=font_path, \n",
    "        width=900, height=400,\n",
    "        background_color='white', \n",
    "        colormap='viridis',\n",
    "        max_words=80\n",
    "    ).generate_from_frequencies(word_freq)\n",
    "    \n",
    "    plt.figure(figsize=(14, 6))\n",
    "    plt.imshow(wc, interpolation='bilinear')\n",
    "    plt.axis('off')\n",
    "    plt.title(f'ğŸ“Š ë””ì‹œì¸ì‚¬ì´ë“œ \"{GALLERY_ID}\" ê°¤ëŸ¬ë¦¬ í‚¤ì›Œë“œ', fontsize=14, fontweight='bold')\n",
    "    plt.show()\n",
    "\n",
    "print(\"\\nğŸ”‘ TOP 15 í‚¤ì›Œë“œ:\")\n",
    "for w, c in word_freq.most_common(15):\n",
    "    print(f\"   {w}: {c}íšŒ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 6. KoBERT ê°ì„±ë¶„ì„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 6-1. KoBERT ëª¨ë¸ ë¡œë“œ\n",
    "# ============================================\n",
    "\n",
    "print(\"ğŸ”„ KoBERT ëª¨ë¸ ë¡œë”©...\")\n",
    "\n",
    "MODEL_NAME = \"snunlp/KR-FinBert-SC\"\n",
    "\n",
    "try:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME)\n",
    "    \n",
    "    sentiment_analyzer = pipeline(\n",
    "        \"sentiment-analysis\",\n",
    "        model=model, tokenizer=tokenizer,\n",
    "        device=0 if torch.cuda.is_available() else -1,\n",
    "        max_length=512, truncation=True\n",
    "    )\n",
    "    \n",
    "    print(f\"âœ… ì™„ë£Œ! ({MODEL_NAME})\")\n",
    "    MODEL_LOADED = True\n",
    "except Exception as e:\n",
    "    print(f\"âŒ ì‹¤íŒ¨: {e}\")\n",
    "    MODEL_LOADED = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 6-2. ê°ì„±ë¶„ì„ í•¨ìˆ˜ (ë””ì‹œ íŠ¹í™”)\n",
    "# ============================================\n",
    "\n",
    "def analyze_sentiment_dc(text):\n",
    "    \"\"\"KoBERT ê°ì„±ë¶„ì„ + ë””ì‹œ íŠ¹í™” ê·œì¹™\"\"\"\n",
    "    \n",
    "    if not text or len(str(text).strip()) < 2:\n",
    "        return 'neutral', 0.5, 0.0\n",
    "    \n",
    "    if MODEL_LOADED:\n",
    "        try:\n",
    "            result = sentiment_analyzer(str(text)[:500])[0]\n",
    "            label = result['label'].lower()\n",
    "            score = result['score']\n",
    "            \n",
    "            if 'positive' in label or 'pos' in label:\n",
    "                return 'positive', score, score\n",
    "            elif 'negative' in label or 'neg' in label:\n",
    "                return 'negative', score, -score\n",
    "            return 'neutral', score, 0.0\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    # ê·œì¹™ ê¸°ë°˜ ë°±ì—… (ë””ì‹œ íŠ¹í™”)\n",
    "    text_lower = str(text).lower()\n",
    "    \n",
    "    pos_patterns = ['ì¸ì •', 'ì¢‹', 'êµ¿', 'ã…‡ã…ˆ', 'ê³µê°', 'ë§ëŠ”ë§', 'íŒ©íŠ¸', 'ë ˆì „ë“œ']\n",
    "    neg_patterns = ['ì•„ë‹ˆ', 'ì‹«', 'ë³„ë¡œ', 'ë…¸ë‹µ', 'ë‹µì—†', 'í•œì‹¬', 'ë©ì²­', 'ë³‘ì‹ ']\n",
    "    \n",
    "    pos_count = sum(1 for p in pos_patterns if p in text_lower)\n",
    "    neg_count = sum(1 for p in neg_patterns if p in text_lower)\n",
    "    \n",
    "    if pos_count > neg_count:\n",
    "        return 'positive', 0.7, 0.5\n",
    "    elif neg_count > pos_count:\n",
    "        return 'negative', 0.7, -0.5\n",
    "    return 'neutral', 0.5, 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 6-3. ì „ì²´ ê°ì„±ë¶„ì„ ìˆ˜í–‰\n",
    "# ============================================\n",
    "\n",
    "print(\"ğŸ”„ ê°ì„±ë¶„ì„ ì§„í–‰ ì¤‘...\")\n",
    "\n",
    "results = [analyze_sentiment_dc(text) for text in df_comments['cleaned_text']]\n",
    "\n",
    "df_comments['sentiment'] = [r[0] for r in results]\n",
    "df_comments['sentiment_confidence'] = [r[1] for r in results]\n",
    "df_comments['sentiment_score'] = [r[2] for r in results]\n",
    "\n",
    "print(\"\\nâœ… ì™„ë£Œ!\")\n",
    "print(\"\\nğŸ“Š ê°ì„± ë¶„í¬:\")\n",
    "print(df_comments['sentiment'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 6-4. ê°ì„±ë¶„ì„ ì‹œê°í™”\n",
    "# ============================================\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "colors = {'positive': '#27ae60', 'neutral': '#95a5a6', 'negative': '#e74c3c'}\n",
    "sentiment_counts = df_comments['sentiment'].value_counts()\n",
    "\n",
    "# ê°ì„± ë¶„í¬\n",
    "axes[0].pie(sentiment_counts.values, \n",
    "            labels=['ê¸ì •', 'ì¤‘ë¦½', 'ë¶€ì •'][:len(sentiment_counts)],\n",
    "            autopct='%1.1f%%', \n",
    "            colors=[colors.get(s, '#95a5a6') for s in sentiment_counts.index])\n",
    "axes[0].set_title('ğŸ¤– KoBERT ê°ì„± ë¶„í¬', fontweight='bold')\n",
    "\n",
    "# ì‹ ë¢°ë„ ë¶„í¬\n",
    "axes[1].hist(df_comments['sentiment_confidence'], bins=20, color='steelblue', alpha=0.7)\n",
    "axes[1].axvline(df_comments['sentiment_confidence'].mean(), color='red', linestyle='--')\n",
    "axes[1].set_xlabel('ì‹ ë¢°ë„')\n",
    "axes[1].set_title('ğŸ“Š ì‹ ë¢°ë„ ë¶„í¬', fontweight='bold')\n",
    "\n",
    "# ê°ì„±ë³„ í…ìŠ¤íŠ¸ ê¸¸ì´\n",
    "df_comments.boxplot(column='text_length', by='sentiment', ax=axes[2])\n",
    "axes[2].set_xlabel('ê°ì„±')\n",
    "axes[2].set_ylabel('í…ìŠ¤íŠ¸ ê¸¸ì´')\n",
    "axes[2].set_title('ğŸ“ˆ ê°ì„±ë³„ í…ìŠ¤íŠ¸ ê¸¸ì´', fontweight='bold')\n",
    "plt.suptitle('')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 7. í˜ì˜¤í‘œí˜„ íƒì§€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 7-1. ë””ì‹œì¸ì‚¬ì´ë“œ íŠ¹í™” í˜ì˜¤í‘œí˜„ íŒ¨í„´\n",
    "# ============================================\n",
    "\n",
    "DC_HATE_PATTERNS = {\n",
    "    'ì¼ë°˜í™”': ['í•­ìƒ', 'ë§¨ë‚ ', 'ëŠ˜', 'ì „ë¶€', 'ê±”ë„¤', 'ìŸ¤ë„¤', 'ê·¸ìª½', 'ë‹ˆë“¤', 'ë¬´ì¡°ê±´', 'ì—­ì‹œë‚˜'],\n",
    "    'ë¹„í•˜': ['í•œì‹¬', 'ë©ì²­', 'ë¬´ì‹', 'ë°”ë³´', 'ë³‘ì‹ ', 'ë¸…ì‹ ', 'ë¯¸ì¹œ', 'ë˜ë¼ì´', 'ì°ë”°', 'ì”¹', 'ì¢†', 'ê¼´í†µ', 'ìˆ˜ì¤€'],\n",
    "    'ì •ì¹˜í˜ì˜¤': ['ì¢ŒíŒŒ', 'ìš°íŒŒ', 'ì¢Œì¢€', 'ë¹¨ê°±ì´', 'ìˆ˜ê¼´', 'ê¼´í†µ', 'ë¬¸ë¹ ', 'ìœ¤ë¹ ', 'ë¯¼ì£¼ë‹¹ì¶©', 'êµ­í˜ì¶©', 'ì°ì¶©'],\n",
    "    'ì„¸ëŒ€í˜ì˜¤': ['í‹€ë”±', 'ê¼°ëŒ€', '586', 'ì Šì€ê²ƒ', 'ëŠ™ì€ì´', 'ìš”ì¦˜ê²ƒë“¤', 'MZì¶©', 'ë¼ë–¼', 'ë…¸ì¸ë„¤'],\n",
    "    'ì„±ë³„í˜ì˜¤': ['í˜ë¯¸', 'í•œë‚¨', 'í•œë…€', 'ê¹€ì¹˜ë…€', 'ë§˜ì¶©', 'ëƒ„ì €', 'ë³´ë¹¨', 'ì¬ê¸°'],\n",
    "    'ì§€ì—­í˜ì˜¤': ['í™ì–´', 'ìª½ë°”ë¦¬', 'ì§±ê¹¨', 'ì „ë¼ë„', 'ê²½ìƒë„'],\n",
    "    'ì™¸ëª¨ë¹„í•˜': ['ëª»ìƒ', 'ë¼ì§€', 'ëš±ë•¡ì´', 'ëŒ€ë¨¸ë¦¬', 'í‚¤ì‘'],\n",
    "}\n",
    "\n",
    "def detect_dc_hate(text):\n",
    "    \"\"\"ë””ì‹œ íŠ¹í™” í˜ì˜¤í‘œí˜„ íƒì§€\"\"\"\n",
    "    if not text: return [], [], 0\n",
    "    text = str(text).lower()\n",
    "    found_types, found_words = [], []\n",
    "    \n",
    "    for htype, patterns in DC_HATE_PATTERNS.items():\n",
    "        for p in patterns:\n",
    "            if p.lower() in text:\n",
    "                if htype not in found_types:\n",
    "                    found_types.append(htype)\n",
    "                found_words.append(p)\n",
    "    \n",
    "    return found_types, found_words, len(found_types)*2 + len(found_words)\n",
    "\n",
    "# ì ìš©\n",
    "print(\"ğŸ”„ í˜ì˜¤í‘œí˜„ íƒì§€ ì¤‘...\")\n",
    "\n",
    "hate_results = [detect_dc_hate(t) for t in df_comments['cleaned_text']]\n",
    "df_comments['hate_types'] = [r[0] for r in hate_results]\n",
    "df_comments['hate_words'] = [r[1] for r in hate_results]\n",
    "df_comments['hate_score'] = [r[2] for r in hate_results]\n",
    "df_comments['has_hate'] = df_comments['hate_types'].apply(lambda x: len(x) > 0)\n",
    "\n",
    "hate_ratio = df_comments['has_hate'].mean() * 100\n",
    "\n",
    "print(f\"\\nâœ… ì™„ë£Œ!\")\n",
    "print(f\"   í˜ì˜¤ í¬í•¨: {df_comments['has_hate'].sum()}ê°œ ({hate_ratio:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 7-2. í˜ì˜¤í‘œí˜„ ìœ í˜•ë³„ ë¶„ì„\n",
    "# ============================================\n",
    "\n",
    "all_hate_types = [t for types in df_comments['hate_types'] for t in types]\n",
    "type_freq = Counter(all_hate_types)\n",
    "\n",
    "print(\"\\nğŸ“Š í˜ì˜¤í‘œí˜„ ìœ í˜•ë³„ ë¹ˆë„:\")\n",
    "print(\"=\"*50)\n",
    "for htype, count in type_freq.most_common():\n",
    "    pct = count / len(df_comments) * 100\n",
    "    bar = 'â–ˆ' * min(count, 15)\n",
    "    print(f\"   {htype:12} | {count:3}ê°œ ({pct:4.1f}%) | {bar}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 7-3. í˜ì˜¤í‘œí˜„ ì‹œê°í™”\n",
    "# ============================================\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "# í˜ì˜¤ ë¹„ìœ¨\n",
    "axes[0].pie([df_comments['has_hate'].sum(), (~df_comments['has_hate']).sum()],\n",
    "            labels=['í˜ì˜¤ í¬í•¨', 'ì •ìƒ'], autopct='%1.1f%%',\n",
    "            colors=['#e74c3c', '#3498db'], explode=[0.05, 0])\n",
    "axes[0].set_title(f'âš ï¸ í˜ì˜¤í‘œí˜„ ë¹„ìœ¨ ({hate_ratio:.1f}%)', fontweight='bold')\n",
    "\n",
    "# ìœ í˜•ë³„ ë¶„í¬\n",
    "if type_freq:\n",
    "    types, counts = zip(*type_freq.most_common())\n",
    "    axes[1].barh(types, counts, color=plt.cm.Reds(np.linspace(0.3, 0.9, len(types))))\n",
    "    axes[1].set_xlabel('ë¹ˆë„')\n",
    "    axes[1].invert_yaxis()\n",
    "axes[1].set_title('ğŸš« í˜ì˜¤í‘œí˜„ ìœ í˜•', fontweight='bold')\n",
    "\n",
    "# ê°ì„± vs í˜ì˜¤\n",
    "cross = pd.crosstab(df_comments['sentiment'], df_comments['has_hate'])\n",
    "cross.columns = ['ì •ìƒ', 'í˜ì˜¤']\n",
    "cross.plot(kind='bar', ax=axes[2], color=['#3498db', '#e74c3c'])\n",
    "axes[2].set_xlabel('ê°ì„±')\n",
    "axes[2].set_title('ğŸ“Š ê°ì„±ë³„ í˜ì˜¤í‘œí˜„', fontweight='bold')\n",
    "axes[2].tick_params(axis='x', rotation=0)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 7-4. í˜ì˜¤í‘œí˜„ í¬í•¨ ëŒ“ê¸€ ì˜ˆì‹œ\n",
    "# ============================================\n",
    "\n",
    "hate_df = df_comments[df_comments['has_hate']].sort_values('hate_score', ascending=False)\n",
    "\n",
    "if len(hate_df) > 0:\n",
    "    print(\"\\nâš ï¸ í˜ì˜¤í‘œí˜„ í¬í•¨ ëŒ“ê¸€ (ì ìˆ˜ ë†’ì€ ìˆœ):\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    for i, (_, row) in enumerate(hate_df.head(8).iterrows(), 1):\n",
    "        text = row['text'][:60] + \"...\" if len(row['text']) > 60 else row['text']\n",
    "        print(f\"\\n{i}. [ì ìˆ˜:{row['hate_score']}] [ìœ í˜•: {', '.join(row['hate_types'])}]\")\n",
    "        print(f\"   {text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 8. ì¢…í•© ë¶„ì„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 8-1. ì¢…í•© ëŒ€ì‹œë³´ë“œ\n",
    "# ============================================\n",
    "\n",
    "fig = plt.figure(figsize=(16, 10))\n",
    "\n",
    "# 1. ê°ì„± ë¶„í¬\n",
    "ax1 = fig.add_subplot(2, 3, 1)\n",
    "sentiment_counts = df_comments['sentiment'].value_counts()\n",
    "ax1.pie(sentiment_counts.values, labels=['ê¸ì •', 'ì¤‘ë¦½', 'ë¶€ì •'][:len(sentiment_counts)],\n",
    "        autopct='%1.1f%%', colors=[colors.get(s, '#95a5a6') for s in sentiment_counts.index])\n",
    "ax1.set_title('ğŸ¤– KoBERT ê°ì„± ë¶„í¬', fontweight='bold')\n",
    "\n",
    "# 2. í˜ì˜¤ ë¹„ìœ¨\n",
    "ax2 = fig.add_subplot(2, 3, 2)\n",
    "ax2.pie([df_comments['has_hate'].sum(), (~df_comments['has_hate']).sum()],\n",
    "        labels=['í˜ì˜¤', 'ì •ìƒ'], autopct='%1.1f%%', colors=['#e74c3c', '#3498db'])\n",
    "ax2.set_title(f'âš ï¸ í˜ì˜¤í‘œí˜„ ë¹„ìœ¨', fontweight='bold')\n",
    "\n",
    "# 3. í‚¤ì›Œë“œ TOP 10\n",
    "ax3 = fig.add_subplot(2, 3, 3)\n",
    "top10 = word_freq.most_common(10)\n",
    "if top10:\n",
    "    words, freqs = zip(*top10)\n",
    "    ax3.barh(words, freqs, color='teal')\n",
    "    ax3.invert_yaxis()\n",
    "ax3.set_title('ğŸ”‘ í‚¤ì›Œë“œ TOP 10', fontweight='bold')\n",
    "\n",
    "# 4. í˜ì˜¤ ìœ í˜•\n",
    "ax4 = fig.add_subplot(2, 3, 4)\n",
    "if type_freq:\n",
    "    types, counts = zip(*type_freq.most_common())\n",
    "    ax4.barh(types, counts, color=plt.cm.Reds(np.linspace(0.3, 0.9, len(types))))\n",
    "    ax4.invert_yaxis()\n",
    "ax4.set_title('ğŸš« í˜ì˜¤í‘œí˜„ ìœ í˜•', fontweight='bold')\n",
    "\n",
    "# 5. í…ìŠ¤íŠ¸ ê¸¸ì´ ë¶„í¬\n",
    "ax5 = fig.add_subplot(2, 3, 5)\n",
    "ax5.hist(df_comments['text_length'], bins=30, color='purple', alpha=0.7)\n",
    "ax5.set_xlabel('í…ìŠ¤íŠ¸ ê¸¸ì´')\n",
    "ax5.set_title('ğŸ“ í…ìŠ¤íŠ¸ ê¸¸ì´ ë¶„í¬', fontweight='bold')\n",
    "\n",
    "# 6. ê°ì„± ì ìˆ˜ ë¶„í¬\n",
    "ax6 = fig.add_subplot(2, 3, 6)\n",
    "scatter_c = df_comments['has_hate'].map({True: '#e74c3c', False: '#3498db'})\n",
    "ax6.scatter(df_comments['sentiment_score'], df_comments['text_length'], c=scatter_c, alpha=0.5, s=20)\n",
    "ax6.set_xlabel('ê°ì„± ì ìˆ˜')\n",
    "ax6.set_ylabel('í…ìŠ¤íŠ¸ ê¸¸ì´')\n",
    "ax6.set_title('ğŸ“ˆ ê°ì„± vs ê¸¸ì´ (ë¹¨ê°•=í˜ì˜¤)', fontweight='bold')\n",
    "\n",
    "plt.suptitle(f'ğŸ“Š ë””ì‹œì¸ì‚¬ì´ë“œ \"{GALLERY_ID}\" ê°¤ëŸ¬ë¦¬ ë¶„ì„ ê²°ê³¼', fontsize=14, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 8-2. ë¶„ì„ ìš”ì•½ ë¦¬í¬íŠ¸\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"ğŸ“‹ ë””ì‹œì¸ì‚¬ì´ë“œ '{GALLERY_ID}' ê°¤ëŸ¬ë¦¬ ë¶„ì„ ê²°ê³¼\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\n[1] ë°ì´í„° ê°œìš”\")\n",
    "print(f\"   - ê°¤ëŸ¬ë¦¬: {GALLERY_ID}\")\n",
    "print(f\"   - í‚¤ì›Œë“œ: {KEYWORD if KEYWORD else '(ì „ì²´)'}\")\n",
    "print(f\"   - ê²Œì‹œê¸€ ìˆ˜: {len(all_posts) if all_posts else 'N/A'}ê°œ\")\n",
    "print(f\"   - ëŒ“ê¸€ ìˆ˜: {len(df_comments):,}ê°œ\")\n",
    "\n",
    "print(f\"\\n[2] KoBERT ê°ì„±ë¶„ì„\")\n",
    "print(f\"   - ëª¨ë¸: {MODEL_NAME if MODEL_LOADED else 'ê·œì¹™ ê¸°ë°˜'}\")\n",
    "for sent, cnt in df_comments['sentiment'].value_counts().items():\n",
    "    print(f\"   - {sent}: {cnt}ê°œ ({cnt/len(df_comments)*100:.1f}%)\")\n",
    "print(f\"   - í‰ê·  ì‹ ë¢°ë„: {df_comments['sentiment_confidence'].mean():.3f}\")\n",
    "\n",
    "print(f\"\\n[3] í˜ì˜¤í‘œí˜„ ë¶„ì„\")\n",
    "print(f\"   - í˜ì˜¤ í¬í•¨: {df_comments['has_hate'].sum()}ê°œ ({hate_ratio:.1f}%)\")\n",
    "if type_freq:\n",
    "    print(f\"   - ì£¼ìš” ìœ í˜•: {', '.join([f'{t}({c})' for t, c in type_freq.most_common(3)])}\")\n",
    "\n",
    "print(f\"\\n[4] ì£¼ìš” í‚¤ì›Œë“œ\")\n",
    "print(f\"   - {', '.join([w for w, c in word_freq.most_common(10)])}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 8-3. ê²°ê³¼ ì €ì¥\n",
    "# ============================================\n",
    "\n",
    "output_cols = ['text', 'cleaned_text', 'writer', 'sentiment', 'sentiment_confidence',\n",
    "               'has_hate', 'hate_types', 'hate_words', 'hate_score']\n",
    "\n",
    "df_output = df_comments[output_cols].copy()\n",
    "df_output['hate_types'] = df_output['hate_types'].apply(lambda x: ', '.join(x) if x else '')\n",
    "df_output['hate_words'] = df_output['hate_words'].apply(lambda x: ', '.join(x) if x else '')\n",
    "\n",
    "filename = f\"dcinside_{GALLERY_ID}_analysis.csv\"\n",
    "df_output.to_csv(filename, index=False, encoding='utf-8-sig')\n",
    "print(f\"âœ… '{filename}' ì €ì¥ ì™„ë£Œ!\")\n",
    "\n",
    "try:\n",
    "    from google.colab import files\n",
    "    files.download(filename)\n",
    "except:\n",
    "    print(\"ë¡œì»¬: í˜„ì¬ í´ë”ì—ì„œ í™•ì¸í•˜ì„¸ìš”.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# ğŸ“ í•™ìŠµ ì •ë¦¬\n",
    "\n",
    "## ë””ì‹œì¸ì‚¬ì´ë“œ í¬ë¡¤ë§ êµ¬ì¡°\n",
    "```\n",
    "ê°¤ëŸ¬ë¦¬ ID ì„¤ì • â†’ ê²Œì‹œê¸€ ëª©ë¡ ìˆ˜ì§‘ â†’ ëŒ“ê¸€ API í˜¸ì¶œ â†’ ëŒ“ê¸€ ìˆ˜ì§‘\n",
    "```\n",
    "\n",
    "## ì£¼ìš” URL\n",
    "- ì¼ë°˜ ê°¤ëŸ¬ë¦¬: `https://gall.dcinside.com/board/lists/?id=ê°¤ëŸ¬ë¦¬ID`\n",
    "- ë§ˆì´ë„ˆ ê°¤ëŸ¬ë¦¬: `https://gall.dcinside.com/mgallery/board/lists/?id=ê°¤ëŸ¬ë¦¬ID`\n",
    "- ëŒ“ê¸€ API: `https://gall.dcinside.com/board/comment/`\n",
    "\n",
    "## ë””ì‹œ íŠ¹í™” ì „ì²˜ë¦¬\n",
    "- ë°˜ë³µ ë¬¸ì ì •ê·œí™” (ã…‹ã…‹ã…‹ã…‹ â†’ ã…‹ã…‹)\n",
    "- ë””ì‹œì½˜ ì œê±°\n",
    "- ì€ì–´/ë¹„ì†ì–´ ì²˜ë¦¬"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
